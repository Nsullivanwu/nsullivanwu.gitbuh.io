[
  {
    "objectID": "coffeeratingshiny.html",
    "href": "coffeeratingshiny.html",
    "title": "Shiny App in Quarto for Coffee Ratings",
    "section": "",
    "text": "coffeedata &lt;- tidytuesdayR:: tt_load('2020-07-07')\ncoffee_ratings &lt;- coffeedata$coffee_ratings\n\nThe data is provided by James LeDoux and comes from Coffee Quality Database (link: https://github.com/jldbc/coffee-quality-database). The original data is on LeDoux’s Github and was re-posted to Kaggle.com (link: https://www.kaggle.com/datasets/volpatto/coffee-quality-database-from-cqi).\nUsing a shiny app, I will install and interactive graph to show the relation between sweetness level and total cup points by nation of origin.\n\nlibrary(rsconnect)\nlibrary(shiny)\nlibrary(tidytuesdayR)\n\ncoffee_data &lt;- tidytuesdayR::tt_load('2020-07-07')$coffee_ratings\n\n\nui &lt;- fluidPage(\n  titlePanel(\"Coffee Ratings (by Country) Based on Sweetness Levels\"),\n  \n  selectInput(\"country\", \"Select a Country of Origin:\",\n              choices = unique(coffee_data$country_of_origin),\n              selected = \"Ethiopia\"),\n  plotOutput(\"scatterPlot\")\n)\n\nserver &lt;- function(input, output) {\n    new_data &lt;- reactive({\n    coffee_data |&gt;\n      filter(country_of_origin == input$country)\n  })\n    output$scatterPlot &lt;- renderPlot({\n    ggplot(new_data(), aes(x = sweetness, y = total_cup_points)) +\n      geom_point(color = \"black\", size = 3, alpha = 0.7) +\n      labs(\n        title = paste(\"Coffee Ratings for\", input$country),\n        x = \"Sweetness\",\n        y = \"Total Cup Points\"\n      ) +\n      theme_minimal()\n  })\n}\n\nshinyApp(ui = ui, server = server)\n\n\n\ndeployApp()\n\nWaiting for task: 1487826848\n  building: Processing bundle: 9500211\n  building: Parsing manifest\n  building: Building image: 11664376\n  building: Installing system dependencies\n  building: Fetching packages\n  building: Installing packages\n  building: Installing files\n  building: Pushing image: 11664376\n  deploying: Starting instances\n  rollforward: Activating new instances\n  terminating: Stopping old instances"
  },
  {
    "objectID": "miniproject2.html",
    "href": "miniproject2.html",
    "title": "Project 2",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndataset &lt;- read.csv(\"dataset.csv\")\nspotify &lt;- dataset\n\nThe data set “Spotify Tracks Dataset” is originally made by Maharshi Pandya (2022), where is was posted on Kaggle.com (link: https://doi.org/10.34740/KAGGLE/DSV/4372070). The data was originally collected using Spotify’s Web API and Python.\nIt has about 75,000 different tracks that spans over 100 genres. Because the data set is so large, I will try to organize some of it. First, I will see the frequency of each artist and each album.\n\nartist_freq &lt;- spotify |&gt; \n  count(artists, sort = TRUE)\n\nalbum_freq &lt;- spotify |&gt; \n  count(album_name, sort = TRUE)\n\nNow, I want to see the top 10 most frequent songs and top 10 most frequent artists.\n\ntop_10_artists &lt;- head(artist_freq, 10)\ntop_10_album &lt;- head(album_freq, 10)\n\nNow, I want to plot my findings.\n\nggplot(top_10_artists, aes(x = reorder(artists, n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"magenta\") + \n  coord_flip() + \n  labs(title = \"Top 10 most frequent artists\", \n       x = \"artist name\", \n       y = \"count\")\n\n\n\n\n\n\n\nggplot(top_10_album, aes(x = reorder(album_name, n), y = n)) + \n  geom_bar(stat = \"identity\", fill = \"purple\") + \n  coord_flip() + \n  labs(title = \"Top 10 most frequent albums\", \n       x = \"album name\", \n       y = \"count\")\n\n\n\n\n\n\n\n\nMoving on, we are going to look at the song names. I am curious to know if certain words in the song title make it more popular. I am going to look at the most frequent words in song names.\n\nwords &lt;- spotify |&gt;\n  mutate(track_name = tolower(track_name)) |&gt;\n  pull(track_name) |&gt;\n  str_extract_all(\"\\\\b\\\\w+(?:'\\\\w+)?\\\\b\") |&gt;\n  unlist() |&gt;\n  as.data.frame() |&gt;\n  setNames(\"word\") |&gt;\n  count(word, sort = TRUE) |&gt;\n  filter(!(word %in%\n             c(\"the\", \"a\", \"of\", \"and\", \"you\", \"me\", \"i\", \"to\", \"my\"))) |&gt;\n  arrange(desc(n)) |&gt;\n  head(50)\n  view(words)\n\nAlthough, we cannot filter out every filler word in songs, we can still see that there are some words such as “love”, “Christmas”, “life”, or “night”. I want to make a comparison by using graphs to see if having a certain word in the song name makes it more popular. We can calculate the average popularity score to look at the relation between popularity and a certain key word in a song title. Popularity is a quantitative variable in the data set. We take the mean of it to find the average.\nFirst we will look at songs with the word “love” in them\n\nspotify &lt;- spotify |&gt;\n  filter(!is.na(track_name))|&gt;\n  mutate(has_love = ifelse(str_detect(track_name, regex(\"\\\\blove\\\\b\", ignore_case = TRUE )), \"Yes\", \"No\"))\n\npopularity &lt;- spotify |&gt;\n  group_by(has_love) |&gt;\n  summarise(avg_popularity = mean(popularity, na.rm = TRUE))\n\npopularity |&gt;\nggplot(aes(x = has_love, y = avg_popularity, fill = has_love)) + \n  geom_bar(stat = \"identity\", width = 0.8) + \n  labs(title = \"Avg Popularity of songs with the word 'love' in the song title\", \n       x = \"has 'love'\", \n       y = \"avg popularity\") +\n  scale_fill_manual(values = c(\"Yes\" = \"deeppink3\", \"No\" = \"cornsilk4\"))\n\n\n\n\n\n\n\n\nNow we will look at songs with the word “Christmas” in the song name\n\nspotify &lt;- spotify |&gt;\n  filter(!is.na(track_name))|&gt;\n  mutate(has_christmas = ifelse(str_detect(track_name, regex(\"\\\\bchristmas\\\\b\", ignore_case = TRUE )), \"Yes\", \"No\"))\n\npopularity &lt;- spotify |&gt;\n  group_by(has_christmas) |&gt;\n  summarise(avg_popularity = mean(popularity, na.rm = TRUE))\n\npopularity |&gt;\nggplot(aes(x = has_christmas, y = avg_popularity, fill = has_christmas)) + \n  geom_bar(stat = \"identity\", width = 0.8) + \n  labs(title = \"Avg Popularity of songs with the word 'christmas' in the song title\", \n       x = \"has 'christmas'\", \n       y = \"avg popularity\") +\n  scale_fill_manual(values = c(\"Yes\" = \"brown3\", \"No\" = \"darkolivegreen4\"))\n\n\n\n\n\n\n\n  theme_minimal\n\nfunction (base_size = 11, base_family = \"\", base_line_size = base_size/22, \n    base_rect_size = base_size/22) \n{\n    theme_bw(base_size = base_size, base_family = base_family, \n        base_line_size = base_line_size, base_rect_size = base_rect_size) %+replace% \n        theme(axis.ticks = element_blank(), legend.background = element_blank(), \n            legend.key = element_blank(), panel.background = element_blank(), \n            panel.border = element_blank(), strip.background = element_blank(), \n            plot.background = element_blank(), complete = TRUE)\n}\n&lt;bytecode: 0xf133fb0&gt;\n&lt;environment: namespace:ggplot2&gt;\n\n\nLastly, we will look at songs with the word “night” in them\n\nspotify &lt;- spotify |&gt;\n  filter(!is.na(track_name))|&gt;\n  mutate(has_night = ifelse(str_detect(track_name, regex(\"\\\\bnight\\\\b\", ignore_case = TRUE )), \"Yes\", \"No\"))\n\npopularity &lt;- spotify |&gt;\n  group_by(has_night) |&gt;\n  summarise(avg_popularity = mean(popularity, na.rm = TRUE))\n\npopularity |&gt;\nggplot(aes(x = has_night, y = avg_popularity, fill = has_night)) + \n  geom_bar(stat = \"identity\", width = 0.8) + \n  labs(title = \"Avg Popularity of songs with the word 'night' in the song title\", \n       x = \"has 'night'\", \n       y = \"avg popularity\") +\n  scale_fill_manual(values = c(\"Yes\" = \"darkslategrey\", \"No\" = \"lightblue\"))\n\n\n\n\n\n\n\n  theme_minimal\n\nfunction (base_size = 11, base_family = \"\", base_line_size = base_size/22, \n    base_rect_size = base_size/22) \n{\n    theme_bw(base_size = base_size, base_family = base_family, \n        base_line_size = base_line_size, base_rect_size = base_rect_size) %+replace% \n        theme(axis.ticks = element_blank(), legend.background = element_blank(), \n            legend.key = element_blank(), panel.background = element_blank(), \n            panel.border = element_blank(), strip.background = element_blank(), \n            plot.background = element_blank(), complete = TRUE)\n}\n&lt;bytecode: 0xf133fb0&gt;\n&lt;environment: namespace:ggplot2&gt;\n\n\nAs we can see from the 3 charts, the only change in popularity due to a specific word in the song title would be the word “love”. However, the other top words, “night” and “Christmas” have no affect on the popularity of songs.\nAfter looking at these findings, we can see how it may be useful to see how certain words affect the popularity of songs. We can see which words could make a song successful and which words would not through correlation. This would be very helpful to all artists and producers in the music industry. Additionally, this research and data could be applied for other areas of entertainment, such as show names or movie names."
  },
  {
    "objectID": "project4.html",
    "href": "project4.html",
    "title": "Project 4 – SQL",
    "section": "",
    "text": "I will use the data from Wideband Acoustic Immittance (WAI) Database hosted by Smith College. I am using the data to recreate the figure “Mean Absorbance from Each Publication in the WAI Database” from Susan E. Voss Ph.D. It is originally from Resource Review. Ear and Hearing 40(6):p 1481, November/December 2019 (link: https://journals.lww.com/ear-hearing/citation/2019/11000/resource_review.21.aspx)\n\nlibrary(RMariaDB)\nlibrary(tidyverse)\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname= \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n# collect(Measurements)\n\nI started this project by using the SQL query, where I grouped together the data by different categories of “Frequency”, “Year”, “Instrument”, “Identifier”, and “AuthorShortList”. I joined together the PI info and Measurements table to get the AuthorShortList. The table demonstrated the mean absorbance of frequencies starting at 200 Hertz and ending at 8000 Hertz.\n\n    SELECT \n        m.Frequency,\n        m.Identifier,\n        m.Instrument,\n        AVG(m.Absorbance) AS Mean_Absorption, \n        CONCAT(pi.AuthorsShortList, ' (', pi.Year, ')', ' N=', COUNT(DISTINCT CONCAT(m.SubjectNumber, '-', m.Ear)),'; ', m.Instrument) AS Label\n    FROM \n        Measurements m\n    JOIN \n        PI_Info pi\n        ON m.Identifier = pi.Identifier\n    WHERE \n        m.Identifier IN ('Abur_2014', 'Feeney_2017', 'Groon_2015', 'Lewis_2015', 'Lui_2008', 'Rosowski_2012', 'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', 'Voss_1994', 'Voss_2010', 'Werner_2010')\n        AND m.frequency BETWEEN 200 AND 8000\n    GROUP BY \n        m.Frequency, \n        m.Identifier, \n        m.Instrument\n    ORDER BY \n        m.Frequency, \n        m.Identifier, \n        m.Instrument\n\nThere is a pattern where absorbance increases when frequency increases. However, after it reaches 1000 Hertz, it started to decrease and drop.\n\nlibrary(ggplot2)\nggplot(new_table, aes(x = Frequency, y = Mean_Absorption, color = Label)) +\n  geom_line(size = 0.6, na.rm = TRUE) +  \n  scale_x_continuous(\n    name = \"Frequency (Hz)\",\n    breaks = c(0, 2000, 3000, 3500, 3850, 6000, 7000, 7500, 8000),\n    labels = c(\"200\", \"400\", \"600\", \"800\", \"1000\", \"2000\", \"4000\", \"6000\", \"8000\")\n  ) +\n  scale_y_continuous(\n    name = \"Mean Absorbance\",\n    limits = c(0, 1), \n    breaks = seq(0, 1, by = 0.1)  \n  ) +\n  labs(\n    title = \"Mean Absorbance From Each Publication in the WAI Database\",  \n    color = NULL \n  ) +\n  theme_minimal() + \n  theme(\n    axis.text = element_text(size = 7),\n    axis.title = element_text(size = 7),\n    plot.title = element_text(size = 10, face = \"bold\", hjust = .5),\n    legend.text = element_text(size = 5),\n    legend.position = c(0.27, 0.9),\n    legend.key.size = unit(0.1, \"cm\"),\n    legend.spacing = unit(0.01, \"cm\"),\n    legend.background = element_rect(color = \"black\", size = .2, fill = \"white\"),\n    aspect.ratio = 1\n  ) \n\n\n\n\n\n\n\n\nNext, I will do the same thing as before, however, will group by “sex” as well. I used the study Abur (2014) to measure and show the average absorbamce of frequencies.\n\nSELECT \n    m.Frequency, \n    s.Sex, \n    AVG(m.Absorbance) AS Avg_Absorbance\nFROM \n    Measurements m\nJOIN \n    Subjects s\nON \n    m.SubjectNumber = s.SubjectNumber\nWHERE \n    m.Identifier = 'Abur_2014'\n    AND s.Sex != 'Unknown'\n    AND m.frequency BETWEEN 200 AND 8000\nGROUP BY \n    m.Frequency, s.Sex\nORDER BY \n    m.Frequency, s.Sex;\n\nThe two different lines show two sexes as subjects. The plot shows how male and female subjects have similar absorbance rates.\n\nlibrary(ggplot2)\n\nggplot(new_table4, aes(x = Frequency, y = Avg_Absorbance, color = Sex)) +\n  geom_line(size = 0.7, na.rm = TRUE) +\n  scale_x_log10(\n    name = \"Frequency (Hz)\",\n    breaks = c(200, 400, 600, 800, 1000, 2000, 4000, 6000, 8000),\n    labels = c(\"200\", \"400\", \"600\", \"800\", \"1000\", \"2000\", \"4000\", \"6000\", \"8000\")\n  ) +\n  scale_y_continuous(\n    name = \"Average Absorbance\",\n    limits = c(0, 1), \n    breaks = seq(0, 1, by = 0.1)\n  ) +\n  labs(\n    title = \"Average Absorbance by Frequency and Gender\",\n    color = NULL \n  ) +\n  theme_minimal() +\n  theme(\n    axis.text = element_text(size = 8),\n    axis.title = element_text(size = 12),\n    plot.title = element_text(size = 16, face = \"bold\"),\n    legend.text = element_text(size = 8),\n    legend.position = c(0.1, 0.9),\n    legend.box.background = element_rect(color = \"black\", fill = \"white\", size = 0.5) \n  )"
  },
  {
    "objectID": "coffee.html",
    "href": "coffee.html",
    "title": "Coffee Ratings Tidy Tuesday Analysis",
    "section": "",
    "text": "coffeedata &lt;- tidytuesdayR:: tt_load('2020-07-07')\ncoffee_ratings &lt;- coffeedata$coffee_ratings\n\nThe data is provided by James LeDoux and comes from Coffee Quality Database (link: https://github.com/jldbc/coffee-quality-database). The original data is on LeDoux’s Github and was re-posted to Kaggle.com (link: https://www.kaggle.com/datasets/volpatto/coffee-quality-database-from-cqi).\n\nlibrary(dplyr)\ncoffee_ratings |&gt;\n  select(total_cup_points, country_of_origin) |&gt;\n  group_by(country_of_origin)\n\n# A tibble: 1,339 × 2\n# Groups:   country_of_origin [37]\n   total_cup_points country_of_origin\n              &lt;dbl&gt; &lt;chr&gt;            \n 1             90.6 Ethiopia         \n 2             89.9 Ethiopia         \n 3             89.8 Guatemala        \n 4             89   Ethiopia         \n 5             88.8 Ethiopia         \n 6             88.8 Brazil           \n 7             88.8 Peru             \n 8             88.7 Ethiopia         \n 9             88.4 Ethiopia         \n10             88.2 Ethiopia         \n# ℹ 1,329 more rows\n\ncoffee_ratings\n\n# A tibble: 1,339 × 43\n   total_cup_points species owner   country_of_origin farm_name lot_number mill \n              &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;             &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;\n 1             90.6 Arabica metad … Ethiopia          \"metad p… &lt;NA&gt;       meta…\n 2             89.9 Arabica metad … Ethiopia          \"metad p… &lt;NA&gt;       meta…\n 3             89.8 Arabica ground… Guatemala         \"san mar… &lt;NA&gt;       &lt;NA&gt; \n 4             89   Arabica yidnek… Ethiopia          \"yidneka… &lt;NA&gt;       wole…\n 5             88.8 Arabica metad … Ethiopia          \"metad p… &lt;NA&gt;       meta…\n 6             88.8 Arabica ji-ae … Brazil             &lt;NA&gt;     &lt;NA&gt;       &lt;NA&gt; \n 7             88.8 Arabica hugo v… Peru               &lt;NA&gt;     &lt;NA&gt;       hvc  \n 8             88.7 Arabica ethiop… Ethiopia          \"aolme\"   &lt;NA&gt;       c.p.…\n 9             88.4 Arabica ethiop… Ethiopia          \"aolme\"   &lt;NA&gt;       c.p.…\n10             88.2 Arabica diamon… Ethiopia          \"tulla c… &lt;NA&gt;       tull…\n# ℹ 1,329 more rows\n# ℹ 36 more variables: ico_number &lt;chr&gt;, company &lt;chr&gt;, altitude &lt;chr&gt;,\n#   region &lt;chr&gt;, producer &lt;chr&gt;, number_of_bags &lt;dbl&gt;, bag_weight &lt;chr&gt;,\n#   in_country_partner &lt;chr&gt;, harvest_year &lt;chr&gt;, grading_date &lt;chr&gt;,\n#   owner_1 &lt;chr&gt;, variety &lt;chr&gt;, processing_method &lt;chr&gt;, aroma &lt;dbl&gt;,\n#   flavor &lt;dbl&gt;, aftertaste &lt;dbl&gt;, acidity &lt;dbl&gt;, body &lt;dbl&gt;, balance &lt;dbl&gt;,\n#   uniformity &lt;dbl&gt;, clean_cup &lt;dbl&gt;, sweetness &lt;dbl&gt;, cupper_points &lt;dbl&gt;, …\n\n\n\nlibrary(ggplot2)\nggplot(coffee_ratings, aes(x = reorder(country_of_origin, total_cup_points), y = total_cup_points, fill = country_of_origin)) +\n    geom_bar(stat = \"identity\") + \n    coord_flip() + \n    labs(title = \"Amount of cup points by country of origin\", \n         x = \"country of origin\", \n         y = \"total cup points\") + \n    theme_minimal() + \n    theme(legend.position = \"name\")\n\n\n\n\n\n\n\n\nUsing Facet Wrapping, I will create a faceted graph to show histograms of total cup points for coffee ratings broken down by each country of origin.\n\ncoffee_ratings &lt;- coffee_ratings |&gt;\n  filter(!is.na(country_of_origin))\n\nggplot(coffee_ratings, aes(x = total_cup_points)) +\n  geom_histogram(binwidth = 2, fill = \"skyblue\", color = \"black\") +\n  facet_wrap(~ country_of_origin) +\n  labs(\n    title = \"Distribution of Total Cup Points by Country of Origin\",\n    x = \"Total Cup Points\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 12, face = \"bold\", hjust = 0.5),\n    strip.text = element_text(size = 10)\n  )"
  },
  {
    "objectID": "rodent_data.html",
    "href": "rodent_data.html",
    "title": "Rodent TidyTuesday Analysis",
    "section": "",
    "text": "rodentdata &lt;- tidytuesdayR:: tt_load('2023-05-02')\nspecies &lt;- rodentdata$species\n\nThis data is from the Portal Project (link: https://portal.weecology.org/). The Weecology research group is a long term ecological research site that monitors rodents, plants, ants, and weather. This dataset serves as the core dataset for the Data Carpentry Ecology material.\n\nlibrary(dplyr)\nweight &lt;- species %&gt;%\n  mutate(difference_weight = meanwgt - juvwgt, )\n\n\nlibrary(ggplot2)\nggplot(weight, aes(x = reorder(commonname, difference_weight), y = difference_weight, fill = difference_weight))+ \n  geom_bar(stat = \"identity\")+\n  coord_flip() +\n  scale_fill_gradient(low = \"yellow\", high = \"darkblue\") + \n  labs(title = \"Difference in Weight for Rodent Species\", \n       x = \"Name of Species\",\n       y = \"Difference in Weight\"\n       ) + \n  theme_minimal()\n\n\n\n\n\n\n\n\nThe white-throated woodrat had the highest difference in weight, at nearly 80, out of all the species of rodents. This is interesting, considereing every other species of rodent has a signicantly smaller weight"
  },
  {
    "objectID": "project3.html",
    "href": "project3.html",
    "title": "Project 3",
    "section": "",
    "text": "In this project, I plan to simulate the probability of a shared birthday. In a room of N number of people, I will see what the probability of at least two people sharing the same birthday is. There is a theory called the birthday paradox, where the probability of two people sharing the same birthday increases with the number of possible pairings, not just the group size.\n\nlibrary(tidyverse)\nlibrary(purrr)\nlibrary(ggplot2)\n\nFirst we will find the birthday paradox for N number of people.\n\nsim_shared_bday &lt;- function(N){\n  bdays &lt;- sample(1:365, N, replace = TRUE)\n  return(length(bdays) != length(unique(bdays)))\n}\n\nNext we will estimate the probability of shared birthdays. We will use multiple simulations using map_lgl() to make sure our estimation is accurate. map_lgl() will apply the function sim_shared_bday to the simulation multiple times and return a True or False.\n\nlibrary(purrr)\n\nestimate_shared_bday &lt;- function(N, num_sims) {\n  outcome &lt;- map_lgl(1:num_sims, ~ sim_shared_bday(N))\n  return(mean(outcome))\n}\n\nNow that we have an estimate of our probability, we will set out parameters and define our probability. I set the group size from 2 to 100 people, and set the number of simulations to 1000 so get more accurate and precise results. I am using map() to apply the estimate_shared_bday to different group sizes. Lastly, I will plot my results.\nIn the plot, the point represent the probability that relate to each group size. The line represents the probability of at least two people sharing the same birthday, as the group size increased.\n\ngrp_size &lt;- 2:100\nnum_sims &lt;- 1000 \nprob &lt;- map_dbl(grp_size, ~ estimate_shared_bday(.x, num_sims))\ndata &lt;- data.frame(group_size = grp_size, probability = prob)\n\nggplot(data, aes(x = group_size, y = probability)) + \n  geom_point(color = \"red\", size = 2) + \n  geom_line(size = 1) + \n  labs(\n    title = \"Shared Birthday Probaility Graph\",\n    x = \"Number of People\",\n    y = \"Probability of Having a Shared Birthday\"\n  ) + \n  theme_minimal()\n\n\n\n\n\n\n\n\nFrom this plot, we can see that as the group size increases, there is a rapid increase in probability. It is an exponential increase in probability as we increase group size. This contradicts what we may have intuitively thought. We naturally would have thought that the probability would increase slowly, however the graph clearly shows it does not. Additionally, the graph shows how after the exponential growth, the slope drastically decreases around a group size of 50 people.\nI want to see where the probability of sharing a birthday with another person is 50%, so I will add a horizontal line to show the intersection.\n\ngrp_size &lt;- 2:100\nnum_sims &lt;- 1000 \nprob &lt;- map_dbl(grp_size, ~ estimate_shared_bday(.x, num_sims))\ndata &lt;- data.frame(group_size = grp_size, probability = prob)\n\nggplot(data, aes(x = group_size, y = probability)) + \n  geom_point(color = \"red\", size = 2) + \n  geom_line(size = 1) + \n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"blue\", size = 1) + \n  scale_x_continuous(breaks = seq(0, 100, by = 5)) + \n  labs(\n    title = \"Shared Birthday Probaility Graph\",\n    x = \"Number of People\",\n    y = \"Probability of Having a Shared Birthday\"\n  ) + \n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can see that the point of interception is around the group size of 23. This means that in a group of 23 people, there would be a 50% probability of at least two people sharing a birthday within the group.\nFor this project, I basically found the probability that at least two people share the same birthday within a group of people. The size of the group changes, and with that there is an exponential increase in the probability. To achieve this, I created two functions that simulate and estimate the probability then graphed it with the y-axis being the probability and the x-axis being the number of people with a min of 0 and a max of 100, however, the function starts with a minimum of 2 people. From this, we were able to see how probability interacts with number of people when finding the probability of at least two people sharing birthdays."
  },
  {
    "objectID": "project5.html#permutation-test",
    "href": "project5.html#permutation-test",
    "title": "Birthday Paradox Presentation",
    "section": "Permutation Test",
    "text": "Permutation Test\nBirthday paradox – Harold Davenport (1927) - The birthday paradox (birthday problem) is the fact that there is a 50% or larger chance that two people in a group of 23 have the same birthday"
  },
  {
    "objectID": "project5.html#my-project",
    "href": "project5.html#my-project",
    "title": "Birthday Paradox Presentation",
    "section": "My Project",
    "text": "My Project\n\nfind the birthday paradox for N amount of people\n\n\nsim_shared_bday &lt;- function(N){\n  bdays &lt;- sample(1:365, N, replace = TRUE)\n  return(length(bdays) != length(unique(bdays)))\n}"
  },
  {
    "objectID": "project5.html#estimating-the-probability-of-shared-birthdays",
    "href": "project5.html#estimating-the-probability-of-shared-birthdays",
    "title": "Birthday Paradox Presentation",
    "section": "Estimating the Probability of Shared Birthdays",
    "text": "Estimating the Probability of Shared Birthdays\n\nmultiple simulations using sapply()\n\n\nestimate_shared_bday &lt;- function(N, num_sims){\n  outcome &lt;- sapply(1:num_sims, function(x) sim_shared_bday(N))\n  return(mean(outcome))\n}"
  },
  {
    "objectID": "project5.html#set-the-parameters-define-our-probability-and-plot",
    "href": "project5.html#set-the-parameters-define-our-probability-and-plot",
    "title": "Birthday Paradox Presentation",
    "section": "Set the Parameters, Define our Probability, and Plot",
    "text": "Set the Parameters, Define our Probability, and Plot\n\ngrp_size &lt;- 2:100\nnum_sims &lt;- 1000 \nprob &lt;- map_dbl(grp_size, ~ estimate_shared_bday(.x, num_sims))\ndata &lt;- data.frame(group_size = grp_size, probability = prob)\n\nggplot(data, aes(x = group_size, y = probability)) + \n  geom_point(color = \"red\", size = 2) + \n  geom_line(size = 1) + \n  labs(\n    title = \"Shared Birthday Probaility Graph\",\n    x = \"Amount of People\",\n    y = \"Probability of Having a Shared Birthday\"\n  ) + \n  theme_minimal()"
  },
  {
    "objectID": "project5.html#in-comparison-to-the-50-threshhold",
    "href": "project5.html#in-comparison-to-the-50-threshhold",
    "title": "Birthday Paradox Presentation",
    "section": "In Comparison to the 50% Threshhold",
    "text": "In Comparison to the 50% Threshhold\n\ngrp_size &lt;- 2:100\nnum_sims &lt;- 1000 \nprob &lt;- map_dbl(grp_size, ~ estimate_shared_bday(.x, num_sims))\ndata &lt;- data.frame(group_size = grp_size, probability = prob)\n\nggplot(data, aes(x = group_size, y = probability)) + \n  geom_point(color = \"red\", size = 2) + \n  geom_line(size = 1) + \n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"blue\", size = 1) + \n  scale_x_continuous(breaks = seq(0, 100, by = 5)) + \n  labs(\n    title = \"Shared Birthday Probaility Graph\",\n    x = \"Amount of People\",\n    y = \"Probability of Having a Shared Birthday\"\n  ) + \n  theme_minimal()"
  },
  {
    "objectID": "project5.html#takeaways",
    "href": "project5.html#takeaways",
    "title": "Birthday Paradox Presentation",
    "section": "Takeaways",
    "text": "Takeaways\n\nIncrease in group size increases –&gt; rapid increase in probability (exponential)\nContradicts intuitive prediction –&gt; The probability would increase slowly\nAfter exponential growth –&gt; Slope decreases (at 50 people)"
  },
  {
    "objectID": "Resume.html",
    "href": "Resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download my resume"
  }
]